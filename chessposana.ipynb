{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chess Position Analyzer -- Expects pgn to be on one line and no spaces after move number:\n",
    "### This may require prepping the portable game notation (PGN) as it is versatile and allows for more variations of play \n",
    "### (like: FisherRandom or various time controls and tournament notations e.g.: Swiss or Round Robin).  Typically we can\n",
    "### just filter out the extra information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook tests a neccesary core feature extraction from the portable game notation.  \n",
    "#####  The position of each piece on the chess board is not readily availble from the list of moves.  However, the algebraic notation is fairly unambiguous and since, memory is rather cheap and widely availble: converting the moves to a set of positions for the sake of abstracting the moves into a wider context makes our search for novel associations to other games easier to query.  This association allows us to empirically test the relative strength of a position for one side or the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first coding cell simply looks at the first game of the All Master Game (allMGs.pgn) in pgn format.\n",
    "#####  The allMGs.pgn file was prepared from a repository of games that came with a chess engine called Hiracs, version released for 2016.  This game set goes back twenty years prior to 2016 or 1995.  The highly biased, currated set of top level games gradually increases in sample size over the years.  We need a game to test the feature extraction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Event \"FIDE WGP Ankara 2012\"]\n",
      "[Site \"Ankara TUR\"]\n",
      "[Date \"2012.09.17\"]\n",
      "[Round \"2\"]\n",
      "[White \"Koneru, Humpy\"]\n",
      "[Black \"Zhao, Xue\"]\n",
      "[Result \"1/2-1/2\"]\n",
      "[BlackElo \"2549\"]\n",
      "[ECO \"A30\"]\n",
      "[EventDate \"2012.09.16\"]\n",
      "[WhiteElo \"2593\"]\n",
      "\n",
      "1.Nf3 Nf6 2.c4 e6 3.g3 b6 4.Bg2 Bb7 5.O-O c5 6.Nc3 Be7 7.d4 cxd4 8.Qxd4 d6\n",
      "9.b3 Nbd7 10.Rd1 a6 11.e4 Qc8 12.Bb2 O-O 13.h3 Rd8 14.Qe3 Qc7 15.Rd2 Rac8\n",
      "16.Nd4 Bf8 17.Re1 Qb8 18.Qe2 Re8 19.Nc2 Nc5 20.b4 Ncd7 21.f4 Red8 22.Red1 Qc7\n",
      "23.Ne3 h6 24.a3 Nh7 25.h4 Be7 26.Bf3 Ndf8 27.Qf2 Qb8 28.Qe2 Qc7 29.Rd3 Qb8\n",
      "30.R3d2 Qc7 31.Rd3 Qb8 32.R3d2 \n"
     ]
    }
   ],
   "source": [
    "fn = \"allMGs.pgn\"\n",
    "f = open(fn)\n",
    "line = f.read(553)\n",
    "f.close()\n",
    "print (line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo filter:\n",
    "##### In the previous code block we simply repeated the content of the first game of the file.  Here we are actually filtering the moves from the commentary on the game.  Most games repeat the results found in the commentary at the end of the move list.  Since, we do not see the drawn result at the end of the move list we most likely need to read more bytes in order to reach that point in the move list.  As for now I simply want to code up the rules for the movement of the pieces as this is the key to extracting the placement of the pieces at each move of the game, aka: Forsyth-Edwards Notation or FEN.\n",
    "##### The last line demostrates the range of representational board positions for characters that we'll parse from the algebraic notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.Nf3 Nf6 2.c4 e6 3.g3 b6 4.Bg2 Bb7 5.O-O c5 6.Nc3 Be7 7.d4 cxd4 8.Qxd4 d6 9.b3 Nbd7 10.Rd1 a6 11.e4 Qc8 12.Bb2 O-O 13.h3 Rd8 14.Qe3 Qc7 15.Rd2 Rac8 16.Nd4 Bf8 17.Re1 Qb8 18.Qe2 Re8 19.Nc2 Nc5 20.b4 Ncd7 21.f4 Red8 22.Red1 Qc7 23.Ne3 h6 24.a3 Nh7 25.h4 Be7 26.Bf3 Ndf8 27.Qf2 Qb8 28.Qe2 Qc7 29.Rd3 Qb8 30.R3d2 Qc7 31.Rd3 Qb8 32.R3d2 \n",
      "[Event \"FIDE WGP Ankara 2012\"][Site \"Ankara TUR\"][Date \"2012.09.17\"][Round \"2\"][White \"Koneru, Humpy\"][Black \"Zhao, Xue\"][Result \"1/2-1/2\"][BlackElo \"2549\"][ECO \"A30\"][EventDate \"2012.09.16\"][WhiteElo \"2593\"]\n",
      "01-8:a-h[4849-56:97-104]\n"
     ]
    }
   ],
   "source": [
    "moves = \"\"\n",
    "comments = \"\"\n",
    "lines = line.split(\"\\n\")\n",
    "for l in lines:\n",
    "    if l.startswith(\"[\"):\n",
    "        comments = comments + l\n",
    "    else:\n",
    "        moves = moves +\" \"+ l\n",
    "print (moves)\n",
    "print (comments)\n",
    "print (\"01-8:a-h[\"+str(ord('0'))+str(ord('1'))+\"-\"+str(ord('8'))+\":\"+str(ord('a'))+\"-\"+str(ord('h'))+\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo feature extraction: convert move (algebraic notation) to position (FEN)\n",
    "##### Our goal is to query similar positions and rank the next move or candidate moves from a given position, empirically.  To this end we need not follow FEN precisely, such things as: \"the right to castle\" and \"whose turn\" are superfluous to our drive.  We simply want to capture the state of the board with respect to the location of pieces.  So, we need to encode the meaning of the move and track it from an initial board configuration through to the last move or end of the game; accounting for captures, castling and special moves (such as promotions and en pesant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335\n",
      "1.Nf3\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8g8c8f8e8d8a7b7c7d7e7f7g7h7a1h1b1f3c1f1e1d1a2b2c2d2e2f2g2h2\n",
      "Nf6\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8f6c8f8e8d8a7b7c7d7e7f7g7h7a1h1b1f3c1f1e1d1a2b2c2d2e2f2g2h2\n",
      "2.c4\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8f6c8f8e8d8a7b7c7d7e7f7g7h7a1h1b1f3c1f1e1d1a2b2c4d2e2f2g2h2\n",
      "e6\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8f6c8f8e8d8a7b7c7d7e6f7g7h7a1h1b1f3c1f1e1d1a2b2c4d2e2f2g2h2\n",
      "3.g3\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8f6c8f8e8d8a7b7c7d7e6f7g7h7a1h1b1f3c1f1e1d1a2b2c4d2e2f2g3h2\n",
      "b6\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8f6c8f8e8d8a7b6c7d7e6f7g7h7a1h1b1f3c1f1e1d1a2b2c4d2e2f2g3h2\n",
      "4.Bg2\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8f6c8f8e8d8a7b6c7d7e6f7g7h7a1h1b1f3c1g2e1d1a2b2c4d2e2f2g3h2\n",
      "Bb7\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8f6b7f8e8d8a7b6c7d7e6f7g7h7a1h1b1f3c1g2e1d1a2b2c4d2e2f2g3h2\n",
      "5.O-O\n",
      "c5\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8f6b7f8e8d8a7b6c5d7e6f7g7h7a1f1b1f3c1g2g1d1a2b2c4d2e2f2g3h2\n",
      "6.Nc3\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8f6b7f8e8d8a7b6c5d7e6f7g7h7a1f1c3f3c1g2g1d1a2b2c4d2e2f2g3h2\n",
      "Be7\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8f6b7e7e8d8a7b6c5d7e6f7g7h7a1f1c3f3c1g2g1d1a2b2c4d2e2f2g3h2\n",
      "7.d4\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8f6b7e7e8d8a7b6c5d7e6f7g7h7a1f1c3f3c1g2g1d1a2b2c4d4e2f2g3h2\n",
      "cxd4\n",
      "RRNNBBKQPPPPPPPPrrnnbbkqppppppp/a8h8b8f6b7e7e8d8a7b6d4d7e6f7g7h7a1f1c3f3c1g2g1d1a2b2c4e2f2g3h2\n",
      "8.Qxd4\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8h8b8f6b7e7e8d8a7b6d7e6f7g7h7a1f1c3f3c1g2g1d4a2b2c4e2f2g3h2\n",
      "d6\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8h8b8f6b7e7e8d8a7b6d6e6f7g7h7a1f1c3f3c1g2g1d4a2b2c4e2f2g3h2\n",
      "9.b3\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8h8b8f6b7e7e8d8a7b6d6e6f7g7h7a1f1c3f3c1g2g1d4a2b3c4e2f2g3h2\n",
      "Nbd7\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8h8d7f6b7e7e8d8a7b6d6e6f7g7h7a1f1c3f3c1g2g1d4a2b3c4e2f2g3h2\n",
      "10.Rd1\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8h8d7f6b7e7e8d8a7b6d6e6f7g7h7a1d1c3f3c1g2g1d4a2b3c4e2f2g3h2\n",
      "a6\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8h8d7f6b7e7e8d8a6b6d6e6f7g7h7a1d1c3f3c1g2g1d4a2b3c4e2f2g3h2\n",
      "11.e4\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8h8d7f6b7e7e8d8a6b6d6e6f7g7h7a1d1c3f3c1g2g1d4a2b3c4e4f2g3h2\n",
      "Qc8\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8h8d7f6b7e7e8c8a6b6d6e6f7g7h7a1d1c3f3c1g2g1d4a2b3c4e4f2g3h2\n",
      "12.Bb2\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8h8d7f6b7e7e8c8a6b6d6e6f7g7h7a1d1c3f3b2g2g1d4a2b3c4e4f2g3h2\n",
      "O-O\n",
      "13.h3\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8f8d7f6b7e7g8c8a6b6d6e6f7g7h7a1d1c3f3b2g2g1d4a2b3c4e4f2g3h3\n",
      "Rd8\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8d8d7f6b7e7g8c8a6b6d6e6f7g7h7a1d1c3f3b2g2g1d4a2b3c4e4f2g3h3\n",
      "14.Qe3\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8d8d7f6b7e7g8c8a6b6d6e6f7g7h7a1d1c3f3b2g2g1e3a2b3c4e4f2g3h3\n",
      "Qc7\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8d8d7f6b7e7g8c7a6b6d6e6f7g7h7a1d1c3f3b2g2g1e3a2b3c4e4f2g3h3\n",
      "15.Rd2\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/a8d8d7f6b7e7g8c7a6b6d6e6f7g7h7a1d2c3f3b2g2g1e3a2b3c4e4f2g3h3\n",
      "Rac8\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7f6b7e7g8c7a6b6d6e6f7g7h7a1d2c3f3b2g2g1e3a2b3c4e4f2g3h3\n",
      "16.Nd4\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7f6b7e7g8c7a6b6d6e6f7g7h7a1d2c3d4b2g2g1e3a2b3c4e4f2g3h3\n",
      "Bf8\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7f6b7f8g8c7a6b6d6e6f7g7h7a1d2c3d4b2g2g1e3a2b3c4e4f2g3h3\n",
      "17.Re1\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7f6b7f8g8c7a6b6d6e6f7g7h7e1d2c3d4b2g2g1e3a2b3c4e4f2g3h3\n",
      "Qb8\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7f6b7f8g8b8a6b6d6e6f7g7h7e1d2c3d4b2g2g1e3a2b3c4e4f2g3h3\n",
      "18.Qe2\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7f6b7f8g8b8a6b6d6e6f7g7h7e1d2c3d4b2g2g1e2a2b3c4e4f2g3h3\n",
      "Re8\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8e8d7f6b7f8g8b8a6b6d6e6f7g7h7e1d2c3d4b2g2g1e2a2b3c4e4f2g3h3\n",
      "19.Nc2\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8e8d7f6b7f8g8b8a6b6d6e6f7g7h7e1d2c3c2b2g2g1e2a2b3c4e4f2g3h3\n",
      "Nc5\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8e8c5f6b7f8g8b8a6b6d6e6f7g7h7e1d2c3c2b2g2g1e2a2b3c4e4f2g3h3\n",
      "20.b4\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8e8c5f6b7f8g8b8a6b6d6e6f7g7h7e1d2c3c2b2g2g1e2a2b4c4e4f2g3h3\n",
      "Ncd7\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8e8d7f6b7f8g8b8a6b6d6e6f7g7h7e1d2c3c2b2g2g1e2a2b4c4e4f2g3h3\n",
      "21.f4\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8e8d7f6b7f8g8b8a6b6d6e6f7g7h7e1d2c3c2b2g2g1e2a2b4c4e4f4g3h3\n",
      "Red8\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7f6b7f8g8b8a6b6d6e6f7g7h7e1d2c3c2b2g2g1e2a2b4c4e4f4g3h3\n",
      "22.Red1\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7f6b7f8g8b8a6b6d6e6f7g7h7d1d2c3c2b2g2g1e2a2b4c4e4f4g3h3\n",
      "Qc7\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7f6b7f8g8c7a6b6d6e6f7g7h7d1d2c3c2b2g2g1e2a2b4c4e4f4g3h3\n",
      "23.Ne3\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7f6b7f8g8c7a6b6d6e6f7g7h7d1d2c3e3b2g2g1e2a2b4c4e4f4g3h3\n",
      "h6\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7f6b7f8g8c7a6b6d6e6f7g7h6d1d2c3e3b2g2g1e2a2b4c4e4f4g3h3\n",
      "24.a3\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7f6b7f8g8c7a6b6d6e6f7g7h6d1d2c3e3b2g2g1e2a3b4c4e4f4g3h3\n",
      "Nh7\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7h7b7f8g8c7a6b6d6e6f7g7h6d1d2c3e3b2g2g1e2a3b4c4e4f4g3h3\n",
      "25.h4\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7h7b7f8g8c7a6b6d6e6f7g7h6d1d2c3e3b2g2g1e2a3b4c4e4f4g3h4\n",
      "Be7\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7h7b7e7g8c7a6b6d6e6f7g7h6d1d2c3e3b2g2g1e2a3b4c4e4f4g3h4\n",
      "26.Bf3\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8d7h7b7e7g8c7a6b6d6e6f7g7h6d1d2c3e3b2f3g1e2a3b4c4e4f4g3h4\n",
      "Ndf8\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8f8h7b7e7g8c7a6b6d6e6f7g7h6d1d2c3e3b2f3g1e2a3b4c4e4f4g3h4\n",
      "27.Qf2\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8f8h7b7e7g8c7a6b6d6e6f7g7h6d1d2c3e3b2f3g1f2a3b4c4e4f4g3h4\n",
      "Qb8\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8f8h7b7e7g8b8a6b6d6e6f7g7h6d1d2c3e3b2f3g1f2a3b4c4e4f4g3h4\n",
      "28.Qe2\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8f8h7b7e7g8b8a6b6d6e6f7g7h6d1d2c3e3b2f3g1e2a3b4c4e4f4g3h4\n",
      "Qc7\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8f8h7b7e7g8c7a6b6d6e6f7g7h6d1d2c3e3b2f3g1e2a3b4c4e4f4g3h4\n",
      "29.Rd3\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8f8h7b7e7g8c7a6b6d6e6f7g7h6d1d3c3e3b2f3g1e2a3b4c4e4f4g3h4\n",
      "Qb8\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8f8h7b7e7g8b8a6b6d6e6f7g7h6d1d3c3e3b2f3g1e2a3b4c4e4f4g3h4\n",
      "30.R3d2\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8f8h7b7e7g8b8a6b6d6e6f7g7h6d1d2c3e3b2f3g1e2a3b4c4e4f4g3h4\n",
      "Qc7\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8f8h7b7e7g8c7a6b6d6e6f7g7h6d1d2c3e3b2f3g1e2a3b4c4e4f4g3h4\n",
      "31.Rd3\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8f8h7b7e7g8c7a6b6d6e6f7g7h6d1d3c3e3b2f3g1e2a3b4c4e4f4g3h4\n",
      "Qb8\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8f8h7b7e7g8b8a6b6d6e6f7g7h6d1d3c3e3b2f3g1e2a3b4c4e4f4g3h4\n",
      "32.R3d2\n",
      "RRNNBBKQPPPPPPPrrnnbbkqppppppp/c8d8f8h7b7e7g8b8a6b6d6e6f7g7h6d1d2c3e3b2f3g1e2a3b4c4e4f4g3h4\n"
     ]
    }
   ],
   "source": [
    "initial_state = \"RRNNBBKQPPPPPPPPrrnnbbkqpppppppp/a8h8b8g8c8f8e8d8a7b7c7d7e7f7g7h7a1h1b1g1c1f1e1d1a2b2c2d2e2f2g2h2\"\n",
    "states = [\"\",initial_state]\n",
    "PAWN = \"P\"\n",
    "ROOK = \"R\"\n",
    "KNIGHT = \"N\"\n",
    "BISHOP = \"B\"\n",
    "QUEEN = \"Q\"\n",
    "KING = \"K\"\n",
    "CAP = \"x\"\n",
    "def queenMoves(fromHere, toHere, state):\n",
    "    a = fromHere\n",
    "    b = toHere\n",
    "    i = 1\n",
    "    while (i+ord(a[1]))<=ord('8'):\n",
    "        if a[0] == b[0] and chr(ord(a[1])+i) == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if a[0]+chr(ord(a[1])+i) in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 1\n",
    "    while (ord(a[0])-i)>=ord('a'):\n",
    "        if chr(ord(a[0])-i) == b[0] and a[1] == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if chr(ord(a[0])-i)+a[1] in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 1\n",
    "    while (i+ord(a[0]))<=ord('h'):\n",
    "        if chr(ord(a[0])+i) == b[0] and a[1] == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if chr(ord(a[0])+i)+a[1] in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 1\n",
    "    while (ord(a[1])-i)>=ord('1'):\n",
    "        if a[0] == b[0] and chr(ord(a[1])-i) == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if a[0]+chr(ord(a[1])-i) in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 1\n",
    "    while (i+ord(a[0]))<=ord('h') and (i+ord(a[1]))<=ord('8'):\n",
    "        if chr(ord(a[0])+i) == b[0] and chr(ord(a[1])+i) == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if chr(ord(a[0])+i)+chr(ord(a[1])+i) in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 1\n",
    "    while (ord(a[0])-i)>=ord('a') and (i+ord(a[1]))<=ord('8'):\n",
    "        if chr(ord(a[0])-i) == b[0] and chr(ord(a[1])+i) == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if chr(ord(a[0])-i)+chr(ord(a[1])+i) in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 0\n",
    "    while (i+ord(a[0]))<=ord('h') and (ord(a[1])-i)>=ord('1'):\n",
    "        if chr(ord(a[0])+i) == b[0] and chr(ord(a[1])-i) == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if chr(ord(a[0])+i)+chr(ord(a[1])-i) in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 1\n",
    "    while (ord(a[0])-i)>=ord('a') and (ord(a[1])-i)>=ord('1'):\n",
    "        if chr(ord(a[0])-i) == b[0] and chr(ord(a[1])-i) == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if chr(ord(a[0])-i)+chr(ord(a[1])-i) in state:\n",
    "                break\n",
    "        i+=1\n",
    "    return False\n",
    "def rookMoves(fromHere, toHere, state):\n",
    "    a = fromHere\n",
    "    b = toHere\n",
    "    i = 1\n",
    "    while (i+ord(a[1]))<=ord('8'):\n",
    "        if a[0] == b[0] and chr(ord(a[1])+i) == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if a[0]+chr(ord(a[1])+i) in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 1\n",
    "    while (ord(a[0])-i)>=ord('a'):\n",
    "        if chr(ord(a[0])-i) == b[0] and a[1] == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if chr(ord(a[0])-i)+a[1] in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 1\n",
    "    while (i+ord(a[0]))<=ord('h'):\n",
    "        if chr(ord(a[0])+i) == b[0] and a[1] == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if chr(ord(a[0])+i)+a[1] in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 1\n",
    "    while (ord(a[1])-i)>=ord('1'):\n",
    "        if a[0] == b[0] and chr(ord(a[1])-i) == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if a[0]+chr(ord(a[1])-i) in state:\n",
    "                break\n",
    "        i+=1\n",
    "    return False \n",
    "def bishopMoves(fromHere, toHere, state):\n",
    "    a = fromHere\n",
    "    b = toHere\n",
    "    i = 1\n",
    "    while (i+ord(a[0]))<=ord('h') and (i+ord(a[1]))<=ord('8'):\n",
    "        if chr(ord(a[0])+i) == b[0] and chr(ord(a[1])+i) == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if chr(ord(a[0])+i)+chr(ord(a[1])+i) in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 1\n",
    "    while (ord(a[0])-i)>=ord('a') and (i+ord(a[1]))<=ord('8'):\n",
    "        if chr(ord(a[0])-i) == b[0] and chr(ord(a[1])+i) == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if chr(ord(a[0])-i)+chr(ord(a[1])+i) in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 1\n",
    "    while (i+ord(a[0]))<=ord('h') and (ord(a[1])-i)>=ord('1'):\n",
    "        if chr(ord(a[0])+i) == b[0] and chr(ord(a[1])-i) == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if chr(ord(a[0])+i)+chr(ord(a[1])-i) in state:\n",
    "                break\n",
    "        i+=1\n",
    "    i = 1\n",
    "    while (ord(a[0])-i)>=ord('a') and (ord(a[1])-i)>=ord('1'):\n",
    "        if chr(ord(a[0])-i) == b[0] and chr(ord(a[1])-i) == b[1]:\n",
    "            return True\n",
    "        else:\n",
    "            if chr(ord(a[0])-i)+chr(ord(a[1])-i) in state:\n",
    "                break\n",
    "        i+=1\n",
    "    return False\n",
    "def knightMoves(fromHere, toHere):\n",
    "    a = fromHere\n",
    "    b = toHere\n",
    "    if (chr(2+ord(a[0]))==b[0] and chr(1+ord(a[1])) == b[1]):\n",
    "        return True\n",
    "    if (chr(-2+ord(a[0]))==b[0] and chr(-1+ord(a[1])) == b[1]):\n",
    "        return True\n",
    "    if (chr(-2+ord(a[0]))==b[0] and chr(1+ord(a[1])) == b[1]):\n",
    "        return True\n",
    "    if (chr(2+ord(a[0]))==b[0] and chr(-1+ord(a[1])) == b[1]):\n",
    "        return True\n",
    "    if (chr(-1+ord(a[0]))==b[0] and chr(2+ord(a[1])) == b[1]):\n",
    "        return True\n",
    "    if (chr(1+ord(a[0]))==b[0] and chr(2+ord(a[1])) == b[1]):\n",
    "        return True\n",
    "    if (chr(1+ord(a[0]))==b[0] and chr(-2+ord(a[1])) == b[1]):\n",
    "        return True\n",
    "    if (chr(-1+ord(a[0]))==b[0] and chr(-2+ord(a[1])) == b[1]):\n",
    "        return True\n",
    "    return False\n",
    "def display(move, isWhite,states):\n",
    "    PAWN = \"P\"\n",
    "    ROOK = \"R\"\n",
    "    KNIGHT = \"N\"\n",
    "    BISHOP = \"B\"\n",
    "    QUEEN = \"Q\"\n",
    "    KING = \"K\"\n",
    "    CAP = \"x\"\n",
    "    state = states[-1]\n",
    "    if 2 == move.count(\"-\"):\n",
    "        if isWhite:\n",
    "            state = state.replace(\"a1\",\"d1\")\n",
    "            state = state.replace(\"e1\",\"c1\")\n",
    "            states.append(state)\n",
    "            return 0\n",
    "        else:\n",
    "            state = state.replace(\"a8\",\"d8\")\n",
    "            state = state.replace(\"e8\",\"c8\")\n",
    "            states.append(state)\n",
    "            return 0\n",
    "    if 1 == move.count(\"-\"):\n",
    "        if isWhite:\n",
    "            state = state.replace(\"h1\",\"f1\")\n",
    "            state = state.replace(\"e1\",\"g1\")\n",
    "            states.append(state)\n",
    "            return 0\n",
    "        else:\n",
    "            state = state.replace(\"h8\",\"f8\")\n",
    "            state = state.replace(\"e8\",\"g8\")\n",
    "            states.append(state)\n",
    "            return 0\n",
    "    pwnDir = 1\n",
    "    cap = \"\"\n",
    "    psqr = \"\"\n",
    "    nsqr = move[-2:]\n",
    "    if 0>=len(move):\n",
    "        frameinfo = getframeinfo(currentframe())\n",
    "        return frameinfo.lineno\n",
    "    piece = move[0]\n",
    "    if piece != ROOK and piece != BISHOP and piece != KNIGHT and piece != KING and piece != QUEEN:\n",
    "        piece = PAWN\n",
    "    if isWhite:\n",
    "        pwnDir = -1\n",
    "        c = state.split(\"/\")[0].count(piece.lower())\n",
    "        if c == 0:\n",
    "            frameinfo = getframeinfo(currentframe())\n",
    "            return frameinfo.lineno\n",
    "        if -1 == state.find(\"/\"):\n",
    "            frameinfo = getframeinfo(currentframe())\n",
    "            return frameinfo.lineno\n",
    "        i = state.split(\"/\")[0].find(piece.lower())*2\n",
    "        if i >= len(state.split(\"/\")[1]):\n",
    "            frameinfo = getframeinfo(currentframe())\n",
    "            return frameinfo.lineno\n",
    "        d = move[1]\n",
    "        psqr = state.split(\"/\")[1][i]+state.split(\"/\")[1][i+1]\n",
    "        if 2 == c and len(move) > 3 and d != CAP and -1 == psqr.find(d):\n",
    "            psqr = state.split(\"/\")[1][i+2]+state.split(\"/\")[1][i+3]\n",
    "        if piece == PAWN:\n",
    "            psqr = move[0]+chr(pwnDir+ord(nsqr[1]))\n",
    "            if -1 == state.find(psqr) and nsqr[1] == '4':\n",
    "                psqr = nsqr[0]+'2'\n",
    "        if piece == BISHOP and c>=2 and not bishopMoves(psqr,nsqr,state):\n",
    "            psqr = state.split(\"/\")[1][i+2]+state.split(\"/\")[1][i+3]\n",
    "        if piece == QUEEN and c>=2 and not queenMoves(psqr,nsqr,state):\n",
    "            psqr = state.split(\"/\")[1][i+2]+state.split(\"/\")[1][i+3]\n",
    "        if piece == ROOK and c>=2 and not rookMoves(psqr,nsqr,state):\n",
    "            psqr = state.split(\"/\")[1][i+2]+state.split(\"/\")[1][i+3]\n",
    "        if piece == KNIGHT and c>=2 and not knightMoves(psqr,nsqr):\n",
    "            psqr = state.split(\"/\")[1][i+2]+state.split(\"/\")[1][i+3]\n",
    "        if -1 != move.find(CAP):\n",
    "            if -1 < state.split(\"/\")[1].find(nsqr):\n",
    "                cap = state[((int)(state.split(\"/\")[1].find(nsqr)/2))]\n",
    "                state = state.replace(cap,\"\",1)\n",
    "                state = state.replace(nsqr,\"\",1)\n",
    "            else:\n",
    "                cap = state[((int)(state.split(\"/\")[1].find(nsqr[0]+(chr(ord(nsqr[1])+pwnDir)))/2))]\n",
    "                state = state.replace(cap,\"\",1)\n",
    "                state = state.replace(nsqr[0]+(chr(ord(nsqr[1])+pwnDir)),\"\",1)\n",
    "        state = state.replace(psqr,nsqr)\n",
    "        states.append(state)\n",
    "    else:\n",
    "        c = state.split(\"/\")[0].count(piece)\n",
    "        if c == 0:\n",
    "            frameinfo = getframeinfo(currentframe())\n",
    "            return frameinfo.lineno\n",
    "        i = state.split(\"/\")[0].find(piece)*2\n",
    "        if -1 == state.find(\"/\"):\n",
    "            frameinfo = getframeinfo(currentframe())\n",
    "            return frameinfo.lineno\n",
    "        if i >= len(state.split(\"/\")[1]):\n",
    "            frameinfo = getframeinfo(currentframe())\n",
    "            return frameinfo.lineno\n",
    "        d = move[1]\n",
    "        psqr = state.split(\"/\")[1][i]+state.split(\"/\")[1][i+1]\n",
    "        if 2 == c and len(move) > 3 and d != CAP and -1 == psqr.find(d):\n",
    "            psqr = state.split(\"/\")[1][i+2]+state.split(\"/\")[1][i+3]\n",
    "        if piece == PAWN:\n",
    "            psqr = move[0]+(chr(pwnDir+ord(nsqr[1])))\n",
    "            if -1 == state.find(psqr) and nsqr[1] == '5':\n",
    "                psqr = nsqr[0]+'7'\n",
    "        if piece == BISHOP and c>=2 and not bishopMoves(psqr,nsqr,state):\n",
    "            psqr = state.split(\"/\")[1][i+2]+state.split(\"/\")[1][i+3]\n",
    "        if piece == QUEEN and c>=2 and not queenMoves(psqr,nsqr,state):\n",
    "            psqr = state.split(\"/\")[1][i+2]+state.split(\"/\")[1][i+3]\n",
    "        if piece == ROOK and c>=2 and not rookMoves(psqr,nsqr,state):\n",
    "            psqr = state.split(\"/\")[1][i+2]+state.split(\"/\")[1][i+3]\n",
    "        if piece == KNIGHT and c>=2 and not knightMoves(psqr,nsqr):\n",
    "            psqr = state.split(\"/\")[1][i+2]+state.split(\"/\")[1][i+3]\n",
    "        if -1 != move.find(CAP):\n",
    "            if -1 < state.split(\"/\")[1].find(nsqr):\n",
    "                cap = state[((int)(state.split(\"/\")[1].find(nsqr)/2))]\n",
    "                state = state.replace(cap,\"\",1)\n",
    "                state = state.replace(nsqr,\"\",1)\n",
    "            else:\n",
    "                cap = state[((int)(state.split(\"/\")[1].find(nsqr[0]+(chr(ord(nsqr[1])+pwnDir)))/2))]\n",
    "                state = state.replace(cap,\"\",1)\n",
    "                state = state.replace(nsqr[0]+(chr(ord(nsqr[1])+pwnDir)),\"\",1)\n",
    "        state = state.replace(psqr,nsqr)\n",
    "        states.append(state)\n",
    "    print (state)\n",
    "    return 0\n",
    "print (len(moves))\n",
    "for m in moves.split():\n",
    "    print (m)\n",
    "    if -1 < m.find(\".\"):\n",
    "        display(m.split(\".\")[1], True,states)\n",
    "    else:\n",
    "        display(m, False,states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We now want to make sure there are other options for getting to FEN:\n",
    "#### chess may be installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ckan-2.11.0a0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting chess\n",
      "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: chess\n",
      "  Building wheel for chess (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147779 sha256=10904555ea01d0b468fe607e71a1c2515a9bad7efe385d0f1336c8474dce836b\n",
      "  Stored in directory: /Users/edgarjohnson/Library/Caches/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\n",
      "Successfully built chess\n",
      "Installing collected packages: chess\n",
      "Successfully installed chess-1.11.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if the system is missing a local sqlite db then we can install it as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some machine learning extensions can be found in mlxtend and scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ckan-2.11.0a0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting mlxtend\n",
      "  Downloading mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mlxtend) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mlxtend) (1.24.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mlxtend) (1.5.3)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mlxtend) (3.7.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mlxtend) (1.1.1)\n",
      "Collecting joblib>=0.13.2 (from mlxtend)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/edgarjohnson/Library/Python/3.11/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/edgarjohnson/Library/Python/3.11/lib/python/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/edgarjohnson/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib, scikit-learn, mlxtend\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.1\n",
      "    Uninstalling joblib-1.1.1:\n",
      "      Successfully uninstalled joblib-1.1.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed joblib-1.4.2 mlxtend-0.23.4 scikit-learn-1.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlxtend scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The chess provides an api for managing the state of the board:\n",
    "##### Storing the results of reading a large file into a persistent storage such as sqlite allows for more expressivity with the query capabilities and keeps us from having to keep reading the file.\n",
    "##### I've added hashlib for the option of securing some features of the db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import hashlib\n",
    "import chess\n",
    "import chess.pgn\n",
    "from  sqlite3  import  Error\n",
    "from hashlib import blake2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We create a connection to a flat db file for storing converted positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection (db_file) :\n",
    "    conn =  None\n",
    "    try :\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return  conn\n",
    "    except  Error  as  e:\n",
    "        print(e)\n",
    "    return  conn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a generic helper function that will create a table according to the schema passed in on the connection passed in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table (conn, create_table_sql) :\n",
    "    try :\n",
    "        c = conn.cursor()\n",
    "        c.execute(create_table_sql)\n",
    "    except  Error  as  e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following defines the table schema for inserting converted positions into the local db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chess_table ( database ) : \n",
    "    sql_create_positions_table =  \"\"\" CREATE TABLE IF NOT EXISTS positions (\n",
    "                                        id integer PRIMARY KEY,\n",
    "                                        move text NOT NULL,\n",
    "                                        pposition text NOT NULL,\n",
    "                                        rposition text NOT NULL,\n",
    "                                        phash text,\n",
    "                                        mhash text,\n",
    "                                        total integer, \n",
    "                                        total01 integer,\n",
    "                                        total10 integer,\n",
    "                                        total12 integer\n",
    "                                    ); \"\"\" \n",
    "\n",
    "    # create a database connection\n",
    "    conn = create_connection(database)\n",
    "\n",
    "    # create table\n",
    "    if  conn  is   not   None :\n",
    "        # create positions table \n",
    "        create_table(conn, sql_create_positions_table)\n",
    "    else :\n",
    "        print( \"Error! cannot create the database connection.\" )\n",
    "    return conn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following treats the table as a hashmap counter, with the keys being the converted position and unique one-way hashes of the position and move.  The pposition or the state of the board prior to the move, is hashed in phash; while the resultting position after the move is stored into the rposition. +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_position (conn, pposition, move, rposition, result) : \n",
    "    h = blake2b(digest_size=16)\n",
    "    h.update(pposition.encode())\n",
    "    phash = h.hexdigest()\n",
    "    h.update(move.encode())\n",
    "    mhash = h.hexdigest()\n",
    "    usql =  ''' UPDATE positions SET total = ?, total01 = ? , total10 = ? , total12 = ?  WHERE id = ?''' \n",
    "    isql =  ''' INSERT INTO positions(pposition,phash,move,mhash,rposition,total,total01,total10,total12)\n",
    "              VALUES(?,?,?,?,?,?,?,?,?) ''' \n",
    "    cur = conn.cursor()\n",
    "    cur.execute( \"SELECT MAX(total), * FROM positions where mhash = '\"+mhash+\"' and phash = '\"+phash+\"';\" )\n",
    "    rows = cur.fetchall()\n",
    "    if (len(rows)==0 or rows[0][0] == None):\n",
    "      if result==\"0-1\": cur.execute(isql, (pposition,phash,move,mhash,rposition,1,1,0,0))\n",
    "      if result==\"1-0\": cur.execute(isql, (pposition,phash,move,mhash,rposition,1,0,1,0))\n",
    "      if result==\"1/2-1/2\": cur.execute(isql, (pposition,phash,move,mhash,rposition,1,0,0,1))\n",
    "      conn.commit()\n",
    "    else:\n",
    "      print (rows)\n",
    "      if result==\"0-1\": cur.execute(usql,(rows[0][7]+1,rows[0][8]+1,rows[0][9],rows[0][10],rows[0][1]))\n",
    "      if result==\"1-0\": cur.execute(usql,(rows[0][7]+1,rows[0][8],rows[0][9]+1,rows[0][10],rows[0][1]))\n",
    "      if result==\"1/2-1/2\": cur.execute(usql,(rows[0][7]+1,rows[0][8],rows[0][9],rows[0][10]+1,rows[0][1]))\n",
    "      conn.commit()\n",
    "    return  cur.lastrowid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, we can create an entry-point that is based on an actual set of moves or games in pgn format and write the transformed positions to a sqllite file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_games () :\n",
    "    database =  r\"twic1450-2GamesPositions.db\"\n",
    "    conn = create_chess_table( database )\n",
    "    pgn = open(\"twic1458.pgn\",encoding='latin-1')\n",
    "\n",
    "    # create a database connection create_connection(database) \n",
    "    with  conn:\n",
    "      while True:\n",
    "        headers = chess.pgn.read_headers(pgn)\n",
    "        if headers is None:\n",
    "          break\n",
    "        game = chess.pgn.read_game(pgn)\n",
    "        if None == game:\n",
    "          continue\n",
    "        board = game.board()\n",
    "        for move in game.mainline_moves():\n",
    "          out=board.fen()\n",
    "          fin=out.split(\" \")\n",
    "          pposition=fin[0]\n",
    "          alg=board.san(move)\n",
    "          board.push(move)\n",
    "          out=board.fen()\n",
    "          fin=out.split(\" \")\n",
    "          rposition=fin[0]\n",
    "          insert_position(conn,pposition,alg,rposition,headers[\"Result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We simply exercise the entry-point via a top-level call to read_games:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_games()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can build out the ingestion layer for loading into a sqlite db and begin empirically checking various selection criteria or smaller data sets for interesting similarities or patterns with games of interest.  We run this code in the background on the command line against a large dataset of pgn.  After it completes its execution we have a db file which we can explore in another tool for query and db management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once we have prepared our data we can begin exploring / mining the data for hidden structures or frequent patterns and discern various groupings of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following graphic is from the arules visualizer available in R.  Association Rules in python requires a specific data format that requires an additional transformation before we can get to the rules similar to what we get out of the box with R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![arules visualizer from R](RaRulesViz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This graphic shows at a glance the strength of connections from a frequentist point of view.  This emperical way of teasing out interesting patterns and similarities in the data readily provides a set of moves commonly found together and even rarely seen combinations of moves.  I also was able to tease out from the SQLiteStudio a few positions of interest using the following sql:\n",
    "\n",
    "###### select id, move, pposition, rposition, total01, total, CAST(total01 as REAL) / CAST(total as REAL) as m from positions where m > .8 and total > 10\n",
    "\n",
    "#### This was found using from a set of games from a specific week in the collection of games. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Selection criteria](sqlitestudio.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id   move                                          pposition  \\\n",
      "0              1     e4        rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR   \n",
      "1              2     e5      rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR   \n",
      "2              3    Nf3    rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR   \n",
      "3              4    Nc6  rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R   \n",
      "4              5    Bb5  r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNB...   \n",
      "...          ...    ...                                                ...   \n",
      "2053460  2053461    Rg1         1r4k1/7p/p2pR3/2p2rp1/2P2P1b/1P5P/P6K/2BR4   \n",
      "2053461  2053462    Kf7        1r4k1/7p/p2pR3/2p2rp1/2P2P1b/1P5P/P6K/2B3R1   \n",
      "2053462  2053463    Rh6        1r6/5k1p/p2pR3/2p2rp1/2P2P1b/1P5P/P6K/2B3R1   \n",
      "2053463  2053464    Re8        1r6/5k1p/p2p3R/2p2rp1/2P2P1b/1P5P/P6K/2B3R1   \n",
      "2053464  2053465  Rxh7+        4r3/5k1p/p2p3R/2p2rp1/2P2P1b/1P5P/P6K/2B3R1   \n",
      "\n",
      "                                                 rposition  \\\n",
      "0            rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR   \n",
      "1          rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR   \n",
      "2        rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R   \n",
      "3        r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNB...   \n",
      "4        r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/R...   \n",
      "...                                                    ...   \n",
      "2053460        1r4k1/7p/p2pR3/2p2rp1/2P2P1b/1P5P/P6K/2B3R1   \n",
      "2053461        1r6/5k1p/p2pR3/2p2rp1/2P2P1b/1P5P/P6K/2B3R1   \n",
      "2053462        1r6/5k1p/p2p3R/2p2rp1/2P2P1b/1P5P/P6K/2B3R1   \n",
      "2053463        4r3/5k1p/p2p3R/2p2rp1/2P2P1b/1P5P/P6K/2B3R1   \n",
      "2053464         4r3/5k1R/p2p4/2p2rp1/2P2P1b/1P5P/P6K/2B3R1   \n",
      "\n",
      "                                    phash                             mhash  \\\n",
      "0        f6986d7853f8c04450cef40948df26c0  2961cc8d4be6af26236c918c02fafb1b   \n",
      "1        384113b987d29e76b3de566c774566d0  32142f05444ded9470b80140b27ea0f3   \n",
      "2        d181887614adad9103d2206a54a5dee4  122d8f5bcb4c39336516e9c86d52900d   \n",
      "3        08240b41b7a3cd84067e6614f5695b84  2e6ce46f16e112df929f6b274f5cd511   \n",
      "4        2ec051425c4c404c356ce9cca08d6e5e  699d9873bb28e50ef91fef84304cfea1   \n",
      "...                                   ...                               ...   \n",
      "2053460  ba67e221ee545069c256482136c3721f  7a3a7a5adfa3738cf90d087125030fa5   \n",
      "2053461  144ba0672d7049f7fee33fe0e0c90077  e42834dbfe5ccf425c71649830d140b8   \n",
      "2053462  69a828bb2a9b3b64b282fe72b2dcc48d  f96e8858ab4559e6c3d7c19967f39830   \n",
      "2053463  7ce97d2e695abd126be315f2313a0e37  2eaa5c6509292303a74f1a5edba12656   \n",
      "2053464  96d6d78005c6035e698f629aa8b8f003  7f363af118739147e489f23746042191   \n",
      "\n",
      "         total  total01  total10  total12  \n",
      "0        13058     4736     5521     2801  \n",
      "1         3004     1055     1227      722  \n",
      "2         2694      950     1084      660  \n",
      "3         2273      794      926      553  \n",
      "4         1146      379      463      304  \n",
      "...        ...      ...      ...      ...  \n",
      "2053460      1        0        0        1  \n",
      "2053461      1        0        0        1  \n",
      "2053462      1        0        0        1  \n",
      "2053463      1        0        0        1  \n",
      "2053464      1        0        0        1  \n",
      "\n",
      "[2053465 rows x 10 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create and train the decision tree classifier\u001b[39;00m\n\u001b[1;32m     16\u001b[0m clf \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier()\n\u001b[0;32m---> 17\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Plot the decision tree\u001b[39;00m\n\u001b[1;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDecisionTreeClassifier\u001b[39;00m(ClassifierMixin, BaseDecisionTree):\n\u001b[1;32m    705\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A decision tree classifier.\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \n\u001b[1;32m    707\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <tree>`.\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;124;03m    criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;124;03m        The function to measure the quality of a split. Supported criteria are\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;124;03m        \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;124;03m        Shannon information gain, see :ref:`tree_mathematical_formulation`.\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m    splitter : {\"best\", \"random\"}, default=\"best\"\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;124;03m        The strategy used to choose the split at each node. Supported\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m        strategies are \"best\" to choose the best split and \"random\" to choose\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m        the best random split.\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    max_depth : int, default=None\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m        The maximum depth of the tree. If None, then nodes are expanded until\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;124;03m        all leaves are pure or until all leaves contain less than\u001b[39;00m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;124;03m        min_samples_split samples.\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03m    min_samples_split : int or float, default=2\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03m        The minimum number of samples required to split an internal node:\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \n\u001b[1;32m    729\u001b[0m \u001b[38;5;124;03m        - If int, then consider `min_samples_split` as the minimum number.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;124;03m        - If float, then `min_samples_split` is a fraction and\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;124;03m          `ceil(min_samples_split * n_samples)` are the minimum\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;124;03m          number of samples for each split.\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \n\u001b[1;32m    734\u001b[0m \u001b[38;5;124;03m        .. versionchanged:: 0.18\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;124;03m           Added float values for fractions.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \n\u001b[1;32m    737\u001b[0m \u001b[38;5;124;03m    min_samples_leaf : int or float, default=1\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;124;03m        The minimum number of samples required to be at a leaf node.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;124;03m        A split point at any depth will only be considered if it leaves at\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m        least ``min_samples_leaf`` training samples in each of the left and\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;124;03m        right branches.  This may have the effect of smoothing the model,\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;124;03m        especially in regression.\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \n\u001b[1;32m    744\u001b[0m \u001b[38;5;124;03m        - If int, then consider `min_samples_leaf` as the minimum number.\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;124;03m        - If float, then `min_samples_leaf` is a fraction and\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m          `ceil(min_samples_leaf * n_samples)` are the minimum\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;124;03m          number of samples for each node.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \n\u001b[1;32m    749\u001b[0m \u001b[38;5;124;03m        .. versionchanged:: 0.18\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03m           Added float values for fractions.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03m    min_weight_fraction_leaf : float, default=0.0\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;124;03m        The minimum weighted fraction of the sum total of weights (of all\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;124;03m        the input samples) required to be at a leaf node. Samples have\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;124;03m        equal weight when sample_weight is not provided.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \n\u001b[1;32m    757\u001b[0m \u001b[38;5;124;03m    max_features : int, float or {\"sqrt\", \"log2\"}, default=None\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;124;03m        The number of features to consider when looking for the best split:\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \n\u001b[1;32m    760\u001b[0m \u001b[38;5;124;03m        - If int, then consider `max_features` features at each split.\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;124;03m        - If float, then `max_features` is a fraction and\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;124;03m          `max(1, int(max_features * n_features_in_))` features are considered at\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03m          each split.\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03m        - If \"sqrt\", then `max_features=sqrt(n_features)`.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m        - If \"log2\", then `max_features=log2(n_features)`.\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;124;03m        - If None, then `max_features=n_features`.\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \n\u001b[1;32m    768\u001b[0m \u001b[38;5;124;03m        .. note::\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03m            The search for a split does not stop until at least one\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;124;03m            valid partition of the node samples is found, even if it requires to\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;124;03m            effectively inspect more than ``max_features`` features.\u001b[39;00m\n\u001b[1;32m    773\u001b[0m \n\u001b[1;32m    774\u001b[0m \u001b[38;5;124;03m    random_state : int, RandomState instance or None, default=None\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;124;03m        Controls the randomness of the estimator. The features are always\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;124;03m        randomly permuted at each split, even if ``splitter`` is set to\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;124;03m        ``\"best\"``. When ``max_features < n_features``, the algorithm will\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;124;03m        select ``max_features`` at random at each split before finding the best\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;124;03m        split among them. But the best found split may vary across different\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m        runs, even if ``max_features=n_features``. That is the case, if the\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;124;03m        improvement of the criterion is identical for several splits and one\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;124;03m        split has to be selected at random. To obtain a deterministic behaviour\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;124;03m        during fitting, ``random_state`` has to be fixed to an integer.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;124;03m        See :term:`Glossary <random_state>` for details.\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \n\u001b[1;32m    786\u001b[0m \u001b[38;5;124;03m    max_leaf_nodes : int, default=None\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;124;03m        Grow a tree with ``max_leaf_nodes`` in best-first fashion.\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;124;03m        Best nodes are defined as relative reduction in impurity.\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;124;03m        If None then unlimited number of leaf nodes.\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \n\u001b[1;32m    791\u001b[0m \u001b[38;5;124;03m    min_impurity_decrease : float, default=0.0\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;124;03m        A node will be split if this split induces a decrease of the impurity\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;124;03m        greater than or equal to this value.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \n\u001b[1;32m    795\u001b[0m \u001b[38;5;124;03m        The weighted impurity decrease equation is the following::\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \n\u001b[1;32m    797\u001b[0m \u001b[38;5;124;03m            N_t / N * (impurity - N_t_R / N_t * right_impurity\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;124;03m                                - N_t_L / N_t * left_impurity)\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \n\u001b[1;32m    800\u001b[0m \u001b[38;5;124;03m        where ``N`` is the total number of samples, ``N_t`` is the number of\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;124;03m        samples at the current node, ``N_t_L`` is the number of samples in the\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;124;03m        left child, and ``N_t_R`` is the number of samples in the right child.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;124;03m        if ``sample_weight`` is passed.\u001b[39;00m\n\u001b[1;32m    806\u001b[0m \n\u001b[1;32m    807\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.19\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \n\u001b[1;32m    809\u001b[0m \u001b[38;5;124;03m    class_weight : dict, list of dict or \"balanced\", default=None\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;124;03m        Weights associated with classes in the form ``{class_label: weight}``.\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;124;03m        If None, all classes are supposed to have weight one. For\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m        multi-output problems, a list of dicts can be provided in the same\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;124;03m        order as the columns of y.\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \n\u001b[1;32m    815\u001b[0m \u001b[38;5;124;03m        Note that for multioutput (including multilabel) weights should be\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;124;03m        defined for each class of every column in its own dict. For example,\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;124;03m        for four-class multilabel classification weights should be\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;124;03m        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;124;03m        [{1:1}, {2:5}, {3:1}, {4:1}].\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \n\u001b[1;32m    821\u001b[0m \u001b[38;5;124;03m        The \"balanced\" mode uses the values of y to automatically adjust\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;124;03m        weights inversely proportional to class frequencies in the input data\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;124;03m        as ``n_samples / (n_classes * np.bincount(y))``\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \n\u001b[1;32m    825\u001b[0m \u001b[38;5;124;03m        For multi-output, the weights of each column of y will be multiplied.\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \n\u001b[1;32m    827\u001b[0m \u001b[38;5;124;03m        Note that these weights will be multiplied with sample_weight (passed\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;124;03m        through the fit method) if sample_weight is specified.\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \n\u001b[1;32m    830\u001b[0m \u001b[38;5;124;03m    ccp_alpha : non-negative float, default=0.0\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;124;03m        Complexity parameter used for Minimal Cost-Complexity Pruning. The\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;124;03m        subtree with the largest cost complexity that is smaller than\u001b[39;00m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;124;03m        ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;124;03m        :ref:`minimal_cost_complexity_pruning` for details. See\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;124;03m        :ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;124;03m        for an example of such pruning.\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \n\u001b[1;32m    838\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.22\u001b[39;00m\n\u001b[1;32m    839\u001b[0m \n\u001b[1;32m    840\u001b[0m \u001b[38;5;124;03m    monotonic_cst : array-like of int of shape (n_features), default=None\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;124;03m        Indicates the monotonicity constraint to enforce on each feature.\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;124;03m          - 1: monotonic increase\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;124;03m          - 0: no constraint\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;124;03m          - -1: monotonic decrease\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \n\u001b[1;32m    846\u001b[0m \u001b[38;5;124;03m        If monotonic_cst is None, no constraints are applied.\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \n\u001b[1;32m    848\u001b[0m \u001b[38;5;124;03m        Monotonicity constraints are not supported for:\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;124;03m          - multiclass classifications (i.e. when `n_classes > 2`),\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;124;03m          - multioutput classifications (i.e. when `n_outputs_ > 1`),\u001b[39;00m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;124;03m          - classifications trained on data with missing values.\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \n\u001b[1;32m    853\u001b[0m \u001b[38;5;124;03m        The constraints hold over the probability of the positive class.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \n\u001b[1;32m    855\u001b[0m \u001b[38;5;124;03m        Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \n\u001b[1;32m    857\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 1.4\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \n\u001b[1;32m    859\u001b[0m \u001b[38;5;124;03m    Attributes\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03m    classes_ : ndarray of shape (n_classes,) or list of ndarray\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m        The classes labels (single output problem),\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;124;03m        or a list of arrays of class labels (multi-output problem).\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m    feature_importances_ : ndarray of shape (n_features,)\u001b[39;00m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;124;03m        The impurity-based feature importances.\u001b[39;00m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;124;03m        The higher, the more important the feature.\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;124;03m        The importance of a feature is computed as the (normalized)\u001b[39;00m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;124;03m        total reduction of the criterion brought by that feature.  It is also\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;124;03m        known as the Gini importance [4]_.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \n\u001b[1;32m    872\u001b[0m \u001b[38;5;124;03m        Warning: impurity-based feature importances can be misleading for\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;124;03m        high cardinality features (many unique values). See\u001b[39;00m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;124;03m        :func:`sklearn.inspection.permutation_importance` as an alternative.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \n\u001b[1;32m    876\u001b[0m \u001b[38;5;124;03m    max_features_ : int\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;124;03m        The inferred value of max_features.\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m    n_classes_ : int or list of int\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;124;03m        The number of classes (for single output problems),\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;124;03m        or a list containing the number of classes for each\u001b[39;00m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;124;03m        output (for multi-output problems).\u001b[39;00m\n\u001b[1;32m    883\u001b[0m \n\u001b[1;32m    884\u001b[0m \u001b[38;5;124;03m    n_features_in_ : int\u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;124;03m        Number of features seen during :term:`fit`.\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.24\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \n\u001b[0;32m--> 889\u001b[0m \u001b[38;5;124;03m    feature_names_in_ : ndarray of shape (`n_features_in_`,)\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m        Names of features seen during :term:`fit`. Defined only when `X`\u001b[39;00m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;124;03m        has feature names that are all strings.\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \n\u001b[1;32m    893\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 1.0\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \n\u001b[1;32m    895\u001b[0m \u001b[38;5;124;03m    n_outputs_ : int\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;124;03m        The number of outputs when ``fit`` is performed.\u001b[39;00m\n\u001b[1;32m    897\u001b[0m \n\u001b[1;32m    898\u001b[0m \u001b[38;5;124;03m    tree_ : Tree instance\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;124;03m        The underlying Tree object. Please refer to\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;124;03m        ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;124;03m        :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m        for basic usage of these attributes.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;124;03m    DecisionTreeRegressor : A decision tree regressor.\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \n\u001b[1;32m    908\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    -----\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m    The default values for the parameters controlling the size of the trees\u001b[39;00m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;124;03m    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;124;03m    unpruned trees which can potentially be very large on some data sets. To\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;124;03m    reduce memory consumption, the complexity and size of the trees should be\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m    controlled by setting those parameter values.\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m    The :meth:`predict` method operates using the :func:`numpy.argmax`\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m    function on the outputs of :meth:`predict_proba`. This means that in\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;124;03m    case the highest predicted probabilities are tied, the classifier will\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;124;03m    predict the tied class with the lowest index in :term:`classes_`.\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \n\u001b[1;32m    921\u001b[0m \u001b[38;5;124;03m    References\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \n\u001b[1;32m    926\u001b[0m \u001b[38;5;124;03m    .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;03m           and Regression Trees\", Wadsworth, Belmont, CA, 1984.\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \n\u001b[1;32m    929\u001b[0m \u001b[38;5;124;03m    .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;124;03m           Learning\", Springer, 2009.\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;03m           https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;124;03m    >>> from sklearn.datasets import load_iris\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;124;03m    >>> from sklearn.model_selection import cross_val_score\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;124;03m    >>> from sklearn.tree import DecisionTreeClassifier\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;124;03m    >>> clf = DecisionTreeClassifier(random_state=0)\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;124;03m    >>> iris = load_iris()\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;124;03m    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m    ...                             # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    ...\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m    array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;124;03m            0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;66;03m# \"check_input\" is used for optimisation and isn't something to be passed\u001b[39;00m\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;66;03m# around in a pipeline.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m     __metadata_request__predict_proba \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_input\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata_routing\u001b[38;5;241m.\u001b[39mUNUSED}\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py:186\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_support_missing_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 186\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m issparse(X)\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_tags__()\u001b[38;5;241m.\u001b[39minput_tags\u001b[38;5;241m.\u001b[39mallow_nan\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonotonic_cst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:579\u001b[0m, in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRegressorMixin\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mixin class for all regression estimators in scikit-learn.\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    This mixin defines the following functionality:\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m \n\u001b[1;32m    580\u001b[0m \u001b[38;5;124;03m    - set estimator type to `\"regressor\"` through the `estimator_type` tag;\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;124;03m    - `score` method that default to :func:`~sklearn.metrics.r2_score`.\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03m    - enforce that `fit` requires `y` to be passed through the `requires_y` tag,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m      which is done by setting the regressor type tag.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \n\u001b[1;32m    585\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <rolling_your_own_estimator>`.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \n\u001b[1;32m    587\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m    >>> import numpy as np\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m    >>> from sklearn.base import BaseEstimator, RegressorMixin\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m    >>> # Mixin classes should always be on the left-hand side for a correct MRO\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m    >>> class MyEstimator(RegressorMixin, BaseEstimator):\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m    ...     def __init__(self, *, param=1):\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m    ...         self.param = param\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    ...     def fit(self, X, y=None):\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m    ...         self.is_fitted_ = True\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m    ...         return self\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    ...     def predict(self, X):\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    ...         return np.full(shape=X.shape[0], fill_value=self.param)\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m    >>> estimator = MyEstimator(param=0)\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03m    >>> X = np.array([[1, 2], [2, 3], [3, 4]])\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m    >>> y = np.array([-1, 0, 1])\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m    >>> estimator.fit(X, y).predict(X)\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m    array([0, 0, 0])\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;124;03m    >>> estimator.score(X, y)\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m    0.0\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;66;03m# TODO(1.8): Remove this attribute\u001b[39;00m\n\u001b[1;32m    610\u001b[0m     _estimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_array\u001b[39m(\n\u001b[1;32m    737\u001b[0m     array,\n\u001b[1;32m    738\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    753\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    754\u001b[0m ):\n\u001b[1;32m    755\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Input validation on an array, list, sparse matrix or similar.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \n\u001b[1;32m    757\u001b[0m \u001b[38;5;124;03m    By default, the input is checked to be a non-empty 2D array containing\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;124;03m    only finite values. If the dtype of the array is object, attempt\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;124;03m    converting to float, raising on failure.\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \n\u001b[1;32m    761\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03m    array : object\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03m        Input object to check / convert.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \n\u001b[1;32m    766\u001b[0m \u001b[38;5;124;03m    accept_sparse : str, bool or list/tuple of str, default=False\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;124;03m        String[s] representing allowed sparse matrix formats, such as 'csc',\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;124;03m        'csr', etc. If the input is sparse but not in the allowed format,\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;124;03m        it will be converted to the first listed format. True allows the input\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03m        to be any format. False means that a sparse matrix input will\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;124;03m        raise an error.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \n\u001b[1;32m    773\u001b[0m \u001b[38;5;124;03m    accept_large_sparse : bool, default=True\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;124;03m        If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;124;03m        accept_sparse, accept_large_sparse=False will cause it to be accepted\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;124;03m        only if its indices are stored with a 32-bit dtype.\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \n\u001b[1;32m    778\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.20\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m    dtype : 'numeric', type, list of type or None, default='numeric'\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;124;03m        Data type of result. If None, the dtype of the input is preserved.\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;124;03m        If \"numeric\", dtype is preserved unless array.dtype is object.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;124;03m        If dtype is a list of types, conversion on the first type is only\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;124;03m        performed if the dtype of the input is not in the list.\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \n\u001b[1;32m    786\u001b[0m \u001b[38;5;124;03m    order : {'F', 'C'} or None, default=None\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;124;03m        Whether an array will be forced to be fortran or c-style.\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;124;03m        When order is None (default), then if copy=False, nothing is ensured\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;124;03m        about the memory layout of the output array; otherwise (copy=True)\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;124;03m        the memory layout of the returned array is kept as close as possible\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;124;03m        to the original array.\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \n\u001b[1;32m    793\u001b[0m \u001b[38;5;124;03m    copy : bool, default=False\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;124;03m        Whether a forced copy will be triggered. If copy=False, a copy might\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;124;03m        be triggered by a conversion.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \n\u001b[1;32m    797\u001b[0m \u001b[38;5;124;03m    force_writeable : bool, default=False\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;124;03m        Whether to force the output array to be writeable. If True, the returned array\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;124;03m        is guaranteed to be writeable, which may require a copy. Otherwise the\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;124;03m        writeability of the input array is preserved.\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \n\u001b[1;32m    802\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 1.6\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m    force_all_finite : bool or 'allow-nan', default=True\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;124;03m        Whether to raise an error on np.inf, np.nan, pd.NA in array. The\u001b[39;00m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;124;03m        possibilities are:\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \n\u001b[1;32m    808\u001b[0m \u001b[38;5;124;03m        - True: Force all values of array to be finite.\u001b[39;00m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;124;03m        - False: accepts np.inf, np.nan, pd.NA in array.\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;124;03m        - 'allow-nan': accepts only np.nan and pd.NA values in array. Values\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;124;03m          cannot be infinite.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \n\u001b[1;32m    813\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.20\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03m           ``force_all_finite`` accepts the string ``'allow-nan'``.\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \n\u001b[1;32m    816\u001b[0m \u001b[38;5;124;03m        .. versionchanged:: 0.23\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;124;03m           Accepts `pd.NA` and converts it into `np.nan`\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \n\u001b[1;32m    819\u001b[0m \u001b[38;5;124;03m        .. deprecated:: 1.6\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;124;03m           `force_all_finite` was renamed to `ensure_all_finite` and will be removed\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;124;03m           in 1.8.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \n\u001b[1;32m    823\u001b[0m \u001b[38;5;124;03m    ensure_all_finite : bool or 'allow-nan', default=True\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;124;03m        Whether to raise an error on np.inf, np.nan, pd.NA in array. The\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;124;03m        possibilities are:\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \n\u001b[1;32m    827\u001b[0m \u001b[38;5;124;03m        - True: Force all values of array to be finite.\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;124;03m        - False: accepts np.inf, np.nan, pd.NA in array.\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;124;03m        - 'allow-nan': accepts only np.nan and pd.NA values in array. Values\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;124;03m          cannot be infinite.\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \n\u001b[1;32m    832\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 1.6\u001b[39;00m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;124;03m           `force_all_finite` was renamed to `ensure_all_finite`.\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \n\u001b[1;32m    835\u001b[0m \u001b[38;5;124;03m    ensure_non_negative : bool, default=False\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;124;03m        Make sure the array has only non-negative values. If True, an array that\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;124;03m        contains negative values will raise a ValueError.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \n\u001b[1;32m    839\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 1.6\u001b[39;00m\n\u001b[1;32m    840\u001b[0m \n\u001b[1;32m    841\u001b[0m \u001b[38;5;124;03m    ensure_2d : bool, default=True\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;124;03m        Whether to raise a value error if array is not 2D.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \n\u001b[1;32m    844\u001b[0m \u001b[38;5;124;03m    allow_nd : bool, default=False\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;124;03m        Whether to allow array.ndim > 2.\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \n\u001b[1;32m    847\u001b[0m \u001b[38;5;124;03m    ensure_min_samples : int, default=1\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;124;03m        Make sure that the array has a minimum number of samples in its first\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;124;03m        axis (rows for a 2D array). Setting to 0 disables this check.\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \n\u001b[1;32m    851\u001b[0m \u001b[38;5;124;03m    ensure_min_features : int, default=1\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;124;03m        Make sure that the 2D array has some minimum number of features\u001b[39;00m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;124;03m        (columns). The default value of 1 rejects empty datasets.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;124;03m        This check is only enforced when the input data has effectively 2\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;124;03m        dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;124;03m        disables this check.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \n\u001b[1;32m    858\u001b[0m \u001b[38;5;124;03m    estimator : str or estimator instance, default=None\u001b[39;00m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;124;03m        If passed, include the name of the estimator in warning messages.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03m    input_name : str, default=\"\"\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m        The data name used to construct the error message. In particular\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;124;03m        if `input_name` is \"X\" and the data has NaN values and\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m        allow_nan is False, the error message will link to the imputer\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m        documentation.\u001b[39;00m\n\u001b[1;32m    866\u001b[0m \n\u001b[1;32m    867\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 1.1.0\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \n\u001b[1;32m    869\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;124;03m    array_converted : object\u001b[39;00m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;124;03m        The converted and validated array.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \n\u001b[1;32m    874\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;124;03m    >>> from sklearn.utils.validation import check_array\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;124;03m    >>> X = [[1, 2, 3], [4, 5, 6]]\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m    >>> X_checked = check_array(X)\u001b[39;00m\n\u001b[0;32m--> 879\u001b[0m \u001b[38;5;124;03m    >>> X_checked\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;124;03m    array([[1, 2, 3], [4, 5, 6]])\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    882\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, np\u001b[38;5;241m.\u001b[39mmatrix):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     device_other \u001b[38;5;241m=\u001b[39m _single_array_device(array)\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device_ \u001b[38;5;241m!=\u001b[39m device_other:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput arrays use different devices: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device_)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device_other)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m device_\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:893\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    847\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;124;03m    Return the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;124;03m          dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 893\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR'"
     ]
    }
   ],
   "source": [
    "#df = pd.DataFrame()\n",
    "\n",
    "# Connect to SQLite database (or create it if it doesn't exist)\n",
    "conn = sqlite3.connect('twic1450-2GamesPositions.db')\n",
    "\n",
    "# Write the DataFrame to a SQLite table\n",
    "#df.to_sql('positions', conn, if_exists='append', index=True)\n",
    "\n",
    "# Verify by reading the table back into a DataFrame\n",
    "df_from_db = pd.read_sql('SELECT * FROM positions', conn)\n",
    "\n",
    "print(df_from_db)\n",
    "X, y = df_from_db['rposition'], df_from_db['total10']/df_from_db['total']\n",
    "\n",
    "# Create and train the decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "tree.plot_tree(clf, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
